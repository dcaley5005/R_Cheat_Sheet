library(slider)
library(tsibble)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
library.dynam.unload(tsibble())
library.dynam.unload("tsibble")
remove.packages("tsibble")
library(slider)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
library(tidyverse)
library(DT)
library(slider)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
install.packages("tsibble")
library(tsibble)
library(slider)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
detach(tsibble)
detach("tsibble")
unloadNamespace("tsibble")
library(slider)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
library(tsibble)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
library(slider)
library(tsibble)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
unloadNamespace("tsibble")
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slider::slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
library(slider)
library(tsibble)
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slider::slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
covid_wide %>% group_by(is_china) %>%
mutate(
across(c(confirmed, death, recovered),
list(rolling = ~ slide_dbl(., sum, .before = 6, .complete = TRUE))),
across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))
) %>% head(5000) %>% datatable(rownames = F)
covid_wide %>% group_by(is_china) %>%
mutate(
across(c(confirmed, death, recovered),
list(rolling = ~ slider::slide_dbl(., sum, .before = 6, .complete = TRUE))),
across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))
) %>% head(5000) %>% datatable(rownames = F)
library(tsibble)
covid_wide_missing_dates %>% arrange(country, is_china) %>%
datatable(rownames = F)
# The fill function allows for the value previously to be populated.  If we didn't do that we would see NA.
covid_wide_missing_dates %>% as_tsibble(key = c(country, is_china),
index = date) %>%
fill_gaps(confirmed = 0,
death = 0,
recovered = 0) %>%
group_by_key() %>%
tidyr::fill(earth_population,
.direction = "down") %>%
ungroup() %>% datatable(rownames = F)
# https://towardsdatascience.com/what-you-need-to-know-about-the-new-dplyr-1-0-0-7eaaaf6d78ac
### Moves the column to the far left
relocate_example <- mtcars %>%
dplyr::relocate(disp) %>%
head(3)
print(relocate_example)
# moves after a column
relocate_example2 <- mtcars %>%
relocate(starts_with("c"), .after = disp)  %>%
head(3)
print(relocate_example2)
A <- read_csv("rawData/Employees.csv")
B <- read_csv("rawData/EmployeeData.csv")
#Automatically Joins on all fields with the same name
left_join(A,B)
#Looks for the column EmployeeID to join on both tables
left_join(A,B,by="EmployeeID")
#When the column names are different you can specify it like this
left_join(A,B,by=c("EmployeeID"="EmployeeID"))
right_join(A,B)
anti_join(A,B)
full_join(A,B)
inner_join(A,B)
semi_join(A,B)
DepartmentHistory <- read_csv("rawData/DepartmentHistory.csv")
#Department history includes multiple records for a single employee
left_join(A,DepartmentHistory)
#Extract the latest department only
latestDepartment <- DepartmentHistory %>%
arrange(desc(Year)) %>%
distinct(EmployeeID,.keep_all = T)
left_join(A,latestDepartment)
unioning_data <- union_all(A, A)
dt <- read_csv("rawData/EmployeeDataProcessed.csv")
dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department,county,city) %>%
summarise_if(is.numeric,sum) %>%
write_csv("EmployeeSummarised.csv")
this_is_a_list <- c(1,2,3,4,5)
for (l in this_is_a_list) {
print(l)
}
for (l in this_is_a_list) {
z <- if_else(l %% 2 == 0, "even","odd")
print(paste0(as.character(l)," ",z))
}
library(tidyverse)
library(DT)
dt <- read_csv("rawData/CalculatedColumns_EmployeeData.csv")
unique(dt$frequency)  ### This is just like distinct
glimpse(dt) ### see a preview of the data
dt <- dt %>% mutate(
AnnualBaseSalary = ifelse(frequency=="HOURLY",base*40*52,base*5*52),
AnnualTotalCompensation = ifelse(frequency=="HOURLY",total*40*52,total*5*52),
AnnualBonus = AnnualTotalCompensation - AnnualBaseSalary
)
dt %>% top_n(500) %>% datatable(rownames = F)
dt <- read_csv("rawData/EmployeeDataProcessed.csv")
dt <- dt %>% filter(year==2017 & county %in% c("CASCADE","POWELL") | AnnualBase >= 20000)
dt <- dt %>% filter(year %in% 2014:2017 & !county %in% c("CASCADE","POWELL"))
2014:2017
2014.1 %in% 2014:2017
2014.1 >= 2014 & 2014.1 <= 2017
# Original Data set
us_rent_income %>% head() %>%  datatable(rownames = F)
# Pivot Wider Data Set
us_rent_income %>%
select(-moe) %>% pivot_wider(names_from = variable, values_from = estimate) %>% head() %>% datatable(rownames = F)
# Multiple Dimension Pivot Wider
us_rent_income %>%
pivot_wider(names_from = variable, names_sep = "_", values_from = c(estimate, moe)) %>% head() %>%  datatable(rownames = F)
# Placing the seperator any where
us_rent_income %>%
pivot_wider(
names_from = variable,
names_glue = "{variable}_{.value}",
values_from = c(estimate, moe)
) %>% head() %>% datatable(rownames = F)
# Performing aggregations
warpbreaks <- as_tibble(warpbreaks[c("wool", "tension", "breaks")])
warpbreaks %>% datatable(rownames = F)
warpbreaks %>%
pivot_wider(
names_from = wool,
values_from = breaks,
values_fn = mean
) %>% datatable(rownames = F)
relig_income %>% head() %>% datatable(rownames = F)
relig_income %>%
pivot_longer(!religion, names_to = "income", values_to = "count")
billboard %>% head() %>% datatable(rownames = F)
billboard %>%
pivot_longer(
cols = starts_with("wk"),
names_to = "week",
names_prefix = "wk",
values_to = "rank",
values_drop_na = TRUE
) %>% datatable(rownames = F)
# Multiple variables stored in column names
who %>% head() %>% datatable(rownames = F)
who %>% pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = c("diagnosis", "gender", "age"),
names_pattern = "new_?(.*)_(.)(.*)",
values_to = "count"
) %>% head(500) %>% datatable(rownames = F)
dt <- read_csv("rawData/EmployeeDataProcessed.csv")
glimpse(dt)
dt1 <- dt %>% group_by(county) %>%
count() %>%
arrange(desc(n))
dt2 <- dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department) %>%
summarise(
AvgBase = mean(AnnualBase),
MedianBase = median(AnnualBase),
TotalBase = sum(AnnualBase)
)
dt3 <- dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department) %>%
summarise_if(is.numeric,mean)
dt4 <- dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department,year) %>%
summarise(TotalBase = sum(AnnualBase)) %>%
spread(year,TotalBase) #### Transpose data
summary_test <- dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department,year) %>%
summarise(TotalBase = sum(AnnualBase))
covid <- read_csv("https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv")
covid <- covid  %>%
group_by(date, country, type) %>%
summarize(cases = sum(cases)) %>%
ungroup() %>%
mutate(is_china = if_else(country == "China","China","Not China"))
confirmed_cases_china_vs_world <- covid %>%
filter(date <= '2020-03-15' & type == "confirmed") %>%
group_by(is_china, date) %>%
summarise(cases = sum(cases)) %>%
mutate(cum_cases = cumsum(cases))
glimpse(confirmed_cases_china_vs_world)
covid_wide <- covid %>% pivot_wider(names_from = type, values_from = cases) %>% filter(date >= "2020-04-01")
covid_wide_missing_dates <- covid %>% pivot_wider(names_from = type, values_from = cases) %>%
mutate(earth_population = 7800000000) %>%
filter(
date >= "2020-04-01" & date <= "2020-04-10" | date >= "2020-04-15" & date <= "2020-04-20" | date >= "2020-05-01" & date <= "2020-05-10"
)
unloadNamespace("tsibble")
library(slider)
library(tsibble)
### Note if you have tsibble library on it will conflict with slider
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slider::slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
### Looking for complete rolling numbers
covid_wide %>% group_by(is_china) %>%
mutate(
across(c(confirmed, death, recovered),
list(rolling = ~ slider::slide_dbl(., sum, .before = 6, .complete = TRUE))),
across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))
) %>% head(5000) %>% datatable(rownames = F)
library(tsibble)
covid_wide_missing_dates %>% arrange(country, is_china) %>%
datatable(rownames = F)
# The fill function allows for the value previously to be populated.  If we didn't do that we would see NA.
covid_wide_missing_dates %>% as_tsibble(key = c(country, is_china),
index = date) %>%
fill_gaps(confirmed = 0,
death = 0,
recovered = 0) %>%
group_by_key() %>%
tidyr::fill(earth_population,
.direction = "down") %>%
ungroup() %>% datatable(rownames = F)
# https://towardsdatascience.com/what-you-need-to-know-about-the-new-dplyr-1-0-0-7eaaaf6d78ac
### Moves the column to the far left
relocate_example <- mtcars %>%
dplyr::relocate(disp) %>%
head(3)
print(relocate_example)
# moves after a column
relocate_example2 <- mtcars %>%
relocate(starts_with("c"), .after = disp)  %>%
head(3)
print(relocate_example2)
A <- read_csv("rawData/Employees.csv")
B <- read_csv("rawData/EmployeeData.csv")
#Automatically Joins on all fields with the same name
left_join(A,B)
#Looks for the column EmployeeID to join on both tables
left_join(A,B,by="EmployeeID")
#When the column names are different you can specify it like this
left_join(A,B,by=c("EmployeeID"="EmployeeID"))
right_join(A,B)
anti_join(A,B)
full_join(A,B)
inner_join(A,B)
semi_join(A,B)
DepartmentHistory <- read_csv("rawData/DepartmentHistory.csv")
#Department history includes multiple records for a single employee
left_join(A,DepartmentHistory)
#Extract the latest department only
latestDepartment <- DepartmentHistory %>%
arrange(desc(Year)) %>%
distinct(EmployeeID,.keep_all = T)
left_join(A,latestDepartment)
unioning_data <- union_all(A, A)
dt <- read_csv("rawData/EmployeeDataProcessed.csv")
dt %>%
filter(county == "LEWIS AND CLARK") %>%
group_by(department,county,city) %>%
summarise_if(is.numeric,sum) %>%
write_csv("EmployeeSummarised.csv")
this_is_a_list <- c(1,2,3,4,5)
for (l in this_is_a_list) {
print(l)
}
for (l in this_is_a_list) {
z <- if_else(l %% 2 == 0, "even","odd")
print(paste0(as.character(l)," ",z))
}
library(tidyverse)
library(DT)
dt <- read_csv("rawData/CalculatedColumns_EmployeeData.csv")
covid <- read_csv("https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv")
covid <- covid  %>%
group_by(date, country, type) %>%
summarize(cases = sum(cases)) %>%
ungroup() %>%
mutate(is_china = if_else(country == "China","China","Not China"))
covid_wide <- covid %>% pivot_wider(names_from = type, values_from = cases) %>% filter(date >= "2020-04-01")
covid <- read_csv("https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv")
covid <- covid  %>%
group_by(date, country, type) %>%
summarize(cases = sum(cases)) %>%
ungroup() %>%
mutate(is_china = if_else(country == "China","China","Not China"))
covid_wide <- covid %>% pivot_wider(names_from = type, values_from = cases) %>% filter(date >= "2020-04-01")
#unloadNamespace("tsibble")
library(slider)
library(tsibble)
### Note if you have tsibble library on it will conflict with slider
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slider::slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
### Looking for complete rolling numbers
covid_wide %>% group_by(is_china) %>%
mutate(
across(c(confirmed, death, recovered),
list(rolling = ~ slider::slide_dbl(., sum, .before = 6, .complete = TRUE))),
across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))
) %>% head(5000) %>% datatable(rownames = F)
library(tidyverse)
library(DT)
dt <- read_csv("rawData/CalculatedColumns_EmployeeData.csv")
# Original Data set
us_rent_income %>% head() %>%  datatable(rownames = F)
# Pivot Wider Data Set
us_rent_income %>%
select(-moe) %>% pivot_wider(names_from = variable, values_from = estimate) %>% head() %>% datatable(rownames = F)
# Multiple Dimension Pivot Wider
us_rent_income %>%
pivot_wider(names_from = variable, names_sep = "_", values_from = c(estimate, moe)) %>% head() %>%  datatable(rownames = F)
# Placing the seperator any where
us_rent_income %>%
pivot_wider(
names_from = variable,
names_glue = "{variable}_{.value}",
values_from = c(estimate, moe)
) %>% head() %>% datatable(rownames = F)
# Performing aggregations
warpbreaks <- as_tibble(warpbreaks[c("wool", "tension", "breaks")])
warpbreaks %>% datatable(rownames = F)
warpbreaks %>%
pivot_wider(
names_from = wool,
values_from = breaks,
values_fn = mean
) %>% datatable(rownames = F)
relig_income %>% head() %>% datatable(rownames = F)
relig_income %>%
pivot_longer(!religion, names_to = "income", values_to = "count")
billboard %>% head() %>% datatable(rownames = F)
billboard %>%
pivot_longer(
cols = starts_with("wk"),
names_to = "week",
names_prefix = "wk",
values_to = "rank",
values_drop_na = TRUE
) %>% datatable(rownames = F)
# Multiple variables stored in column names
who %>% head() %>% datatable(rownames = F)
who %>% pivot_longer(
cols = new_sp_m014:newrel_f65,
names_to = c("diagnosis", "gender", "age"),
names_pattern = "new_?(.*)_(.)(.*)",
values_to = "count"
) %>% head(500) %>% datatable(rownames = F)
covid <- read_csv("https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv")
covid <- covid  %>%
group_by(date, country, type) %>%
summarize(cases = sum(cases)) %>%
ungroup() %>%
mutate(is_china = if_else(country == "China","China","Not China"))
covid_wide <- covid %>% pivot_wider(names_from = type, values_from = cases) %>% filter(date >= "2020-04-01")
#unloadNamespace("tsibble")
library(slider)
library(tsibble)
### Note if you have tsibble library on it will conflict with slider
covid_wide %>% head(5000) %>% datatable(rownames = F)
### Multiple Metrics by rolling 7 Days
covid_wide %>% group_by(country, is_china) %>%
mutate(across(c(confirmed, death, recovered), list(rolling = ~ slider::slide_dbl(., sum, .before = 6)))) %>%
mutate(across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))) %>%
head(5000) %>% datatable(rownames = F)
### Looking for complete rolling numbers
covid_wide %>% group_by(is_china) %>%
mutate(
across(c(confirmed, death, recovered),
list(rolling = ~ slider::slide_dbl(., sum, .before = 6, .complete = TRUE))),
across(contains("rolling"), list(growth = ~ . / lag(., 6) -1))
) %>% head(5000) %>% datatable(rownames = F)
library(tsibble)
covid_wide_missing_dates %>% arrange(country, is_china) %>%
datatable(rownames = F)
# The fill function allows for the value previously to be populated.  If we didn't do that we would see NA.
covid_wide_missing_dates %>% as_tsibble(key = c(country, is_china),
index = date) %>%
fill_gaps(confirmed = 0,
death = 0,
recovered = 0) %>%
group_by_key() %>%
tidyr::fill(earth_population,
.direction = "down") %>%
ungroup() %>% datatable(rownames = F)
# https://towardsdatascience.com/what-you-need-to-know-about-the-new-dplyr-1-0-0-7eaaaf6d78ac
### Moves the column to the far left
relocate_example <- mtcars %>%
dplyr::relocate(disp) %>%
head(3)
print(relocate_example)
# moves after a column
relocate_example2 <- mtcars %>%
relocate(starts_with("c"), .after = disp)  %>%
head(3)
print(relocate_example2)
this_is_a_list <- c(1,2,3,4,5)
for (l in this_is_a_list) {
print(l)
}
for (l in this_is_a_list) {
z <- if_else(l %% 2 == 0, "even","odd")
print(paste0(as.character(l)," ",z))
}
covid <- read_csv("https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv")
covid <- covid  %>%
group_by(date, country, type) %>%
summarize(cases = sum(cases)) %>%
ungroup() %>%
mutate(is_china = if_else(country == "China","China","Not China"))
covid_wide <- covid %>% pivot_wider(names_from = type, values_from = cases) %>% filter(date >= "2020-04-01")
covid_wide_missing_dates <- covid %>% pivot_wider(names_from = type, values_from = cases) %>%
mutate(earth_population = 7800000000) %>%
filter(
date >= "2020-04-01" & date <= "2020-04-10" |
date >= "2020-04-15" & date <= "2020-04-20" | date >= "2020-05-01" & date <= "2020-05-10"
)
library(tidyverse)
library(DT)
dt <- read_csv("rawData/CalculatedColumns_EmployeeData.csv")
library(stringr)
bgn_date <- "2020-02-01"
ebd_date <- "2020-02-08"
sql <- str_glue("select customer_id, order_id, sales_price from orders where date_order between {bgn_date} and {end_date}")
remove(ebd_date)
bgn_date <- "2020-02-01"
end_date <- "2020-02-08"
sql <- str_glue("select customer_id, order_id, sales_price from orders where date_order between {bgn_date} and {end_date}")
sql
string <- "Dan is awesome!"
remove(string)
random_string <- "Dan is awesome!"
str_detect(random_string,"Dan")
shopping_list <- c("apples x4", "bag of flour", "bag of sugar", "milk x2")
str_extract(shopping_list, "\\d")
str_extract(shopping_list, "[a-z]+")
str_extract(shopping_list, "[a-z]{1,4}")
str_extract(shopping_list, "\\b[a-z]{1,4}\\b")
str_extract(shopping_list, "\\d")
str_extract(shopping_list, "[a-z]+")
str_extract(shopping_list, "[a-z]{1,4}")
str_extract(shopping_list, "\\b[a-z]{1,4}\\b")
gsub(random_string,"Dan","Daniel")
gsub("Dan","Daniel",random_string)
